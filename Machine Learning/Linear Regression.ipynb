{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction : Linear Regression \n",
    "# Classification : Logistic Regression\n",
    "\n",
    "# Variables : # Dependent variable(y) : Quantitative variable (continuous)\n",
    "              # Independent variable(x) : Quantitative\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression : ease of interpreting results\n",
    "\n",
    "# Y(actual) = a+bx (simple linear regression)\n",
    "\n",
    "# Y = A+B1X1+B2X2+......BnXn (multiple linear regression)\n",
    "\n",
    "# A(ALPHA) : Intercept / Random error : Value OF Y ON X-AXIS\n",
    "# B(BETA) :regression Coefficient/Slope : one unit change in independent variable will change dependent variable\n",
    "\n",
    "\n",
    "# ùëì(ùê±i) = ùëè‚ÇÄ + ùëè‚ÇÅùë•‚ÇÅ + ‚ãØ + ùëèiùë•i = Estimated Regression fuction\n",
    "\n",
    "# Yi - ùëì(ùê±i) = residuals\n",
    "\n",
    "# Regression is about determining the best predicted weights, that is the weights corresponding to the smallest residuals.\n",
    "# To get the best weights, you usually minimize the sum of squared residuals (SSR) for all observations\n",
    "# ùëñ = 1, ‚Ä¶, ùëõ: SSR = Œ£·µ¢(ùë¶·µ¢ - ùëì(ùê±·µ¢))¬≤. This approach is called the method of ordinary least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting : occurs when a model can‚Äôt accurately capture the dependencies among data, \n",
    "#                usually as a consequence of its own simplicity. \n",
    "#                It often yields a low ùëÖ¬≤ with known data and bad generalization capabilities \n",
    "#                when applied with new data.\n",
    "\n",
    "# Overfitting : happens when a model learns both dependencies among data and random fluctuations(Î≥ÄÎèô). \n",
    "#               In other words, a model learns the existing data too well. \n",
    "#               Complex models, which have many features or terms, are often prone to overfitting. \n",
    "#               When applied to known data, such models usually yield high ùëÖ¬≤. \n",
    "#               However, they often don‚Äôt generalize well and have significantly lower ùëÖ¬≤ when used with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [15]\n",
      " [25]\n",
      " [35]\n",
      " [45]\n",
      " [55]]\n",
      "[ 5 20 14 32 22 38]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "# Import packages and classes\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Provide data\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([5, 20, 14, 32, 22, 38])\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model and fit it\n",
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.715875613747954\n"
     ]
    }
   ],
   "source": [
    "# Get results\n",
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 5.633333333333329\n",
      "slope: [0.54]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 8.33333333 13.73333333 19.13333333 24.53333333 29.93333333 35.33333333]\n"
     ]
    }
   ],
   "source": [
    "# Predict response\n",
    "\n",
    "y_pred = model.predict(x) #(y_pred = model.intercept_ + model.coef_ * x)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[5.63333333 6.17333333 6.71333333 7.25333333 7.79333333]\n"
     ]
    }
   ],
   "source": [
    "x_new = np.arange(5).reshape((-1, 1))\n",
    "print(x_new)\n",
    "\n",
    "y_new = model.predict(x_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 5  1]\n",
      " [15  2]\n",
      " [25  5]\n",
      " [35 11]\n",
      " [45 15]\n",
      " [55 34]\n",
      " [60 35]]\n",
      "[ 4  5 20 14 32 22 38 43]\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8615939258756775\n",
      "intercept: 5.52257927519819\n",
      "slope: [0.44706965 0.25502548]\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(x, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('slope:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n",
      " 38.78227633 41.27265006]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x) #(y_pred = model.intercept_ + model.coef_ * x)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "# Step 1: Import packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 2a: Provide data\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "\n",
    "# Step 2b: Transform input data\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n",
    "\n",
    "# Step 3: Create a model and fit it\n",
    "model = LinearRegression().fit(x_, y)\n",
    "\n",
    "# Step 4: Get results\n",
    "r_sq = model.score(x_, y)\n",
    "intercept, coefficients = model.intercept_, model.coef_\n",
    "\n",
    "# Step 5: Predict\n",
    "y_pred = model.predict(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.9453701449127822\n"
     ]
    }
   ],
   "source": [
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 0.8430556452395734\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients:\n",
      "[ 2.44828275  0.16160353 -0.15259677  0.47928683 -0.4641851 ]\n"
     ]
    }
   ],
   "source": [
    "print('coefficients:', coefficients, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[ 0.54047408 11.36340283 16.07809622 15.79139    29.73858619 23.50834636\n",
      " 39.05631386 41.92339046]\n"
     ]
    }
   ],
   "source": [
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
